# 视觉大模型猜拳游戏 (Rock–Paper–Scissors, RPS)

## 功能简介
视觉大模型猜拳游戏模块利用通义千问视觉大模型实现机器人与人类玩家的智能猜拳互动。
系统能通过机器人摄像头捕捉人类玩家的手势，并使用视觉大模型进行识别，同时机器人随机出拳判断胜负，并通过肢体动作和语音播报展示结果。

## 使用方法
1. **启动脚本**：运行`start_rps.py`
2. **开始游戏**：说出“猜拳”
3. **出拳**：听到提示后，在摄像头前做出剪刀、石头或布的动作
4. **结果判定**：机器人会做出自己的手势，并宣布胜负结果
5. **再来一局**：说出“再来”可继续游戏

提示：
- 正式使用前需要在代码内设置好API-KEY
- 由于机器人手形不能动，因此我们改用机器人全身来表示不同的动作，具体动作可手动测试`ActionGroups`文件夹内的`jiandao.d6a`、`shitou.d6a`、`bu.d6a`文件。

## 技术实现
- **视觉大模型**：
  - 使用阿里云通义千问视觉语言大模型
  - 通过DashScope API发送图像并识别手势
  - 专门设计的系统提示词引导模型只输出手势类型

- **图像捕获**：
  - 使用OpenCV库捕获高质量图像
  - 保存最近一次的猜拳图像便于后续分析

- **机器人动作**：
  - 根据随机选择的出拳结果，执行相应的动作组
  - 根据猜拳游戏的胜负结果，执行相应的情感表达动作

- **语音交互**：
  - 使用ASR模块处理语音指令
  - 使用TTS模块播报游戏过程和结果

## API配置
- 使用阿里云DashScope API
- 模型：qwen-vl-max-latest
- 正式使用前需要在代码内设置好API-KEY

## 注意事项
- 机器人会在说完“剪刀石头布”后立刻做出它的动作，因此用户做动作的速度需稍快
- 由于机器人手形不能动，因此机器人在做全身动作时，请确保机器人有足够的活动空间执行动作
- API调用可能产生费用，请关注API使用量
- 在适当的光照条件下进行游戏，确保手势能被清晰识别
- 保持手势在摄像头视野中心区域以提高识别准确率